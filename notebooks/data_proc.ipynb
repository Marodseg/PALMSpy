{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisys PALMS Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T08:19:03.770404Z",
     "start_time": "2019-12-03T08:19:03.256484Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T08:19:04.519156Z",
     "start_time": "2019-12-03T08:19:04.504581Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T08:19:14.398048Z",
     "start_time": "2019-12-03T08:19:14.392920Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> .CodeMirror pre { font-size: 120% !important; } </style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style> .CodeMirror pre { font-size: 120% !important; } </style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T17:35:17.295525Z",
     "start_time": "2019-11-15T17:35:17.289448Z"
    }
   },
   "outputs": [],
   "source": [
    "# select data directory\n",
    "\n",
    "work_dir = \"data/raw/NBBB baseline/\"\n",
    "work_dir = \"../test_data/\"\n",
    "acc = \"acc/\"  # accelerometer data (metadata)\n",
    "gps = \"gps/\"  # GPS data (csv format)\n",
    "merge = \"merge/\"\n",
    "\n",
    "# acc and GPS data files have the same name\n",
    "list_file_acc = sorted(os.listdir(work_dir + acc))\n",
    "list_file_gps = sorted(os.listdir(work_dir + gps))\n",
    "\n",
    "# select a file from the list\n",
    "file_gps = list_file_gps[0]\n",
    "file_acc = list_file_acc[0]\n",
    "file_merge = file_acc[:-4] + \"-merged.csv\"\n",
    "print(\"\\n Acc data file :   \" + file_acc)\n",
    "print(\" GPS data file :   \" + file_gps)\n",
    "print(\" Output file   :   \" + file_merge + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T17:36:11.018471Z",
     "start_time": "2019-11-15T17:36:03.003260Z"
    }
   },
   "outputs": [],
   "source": [
    "# read GPS data and create a dataframe\n",
    "\n",
    "path = work_dir + gps + file_gps\n",
    "\n",
    "columns = pd.read_csv(path, sep=',').columns.values.tolist() # extract headers\n",
    "columns = [columns[k].strip() for k in range(len(columns))] # remove initial/final spaces\n",
    "\n",
    "# remove last empty column\n",
    "gps_df = pd.read_csv(path, sep=',', names=columns).drop(columns=['INDEX'])\n",
    "\n",
    "# remove duplicate lines to get read of multiple header rows\n",
    "gps_df = gps_df.drop_duplicates()\n",
    "\n",
    "# remove the first row which contains a repetition of the header\n",
    "gps_df = gps_df.drop(gps_df.index[0])\n",
    "gps_df = gps_df.reset_index()\n",
    "gps_df = gps_df.drop(columns=['index'])\n",
    "\n",
    "try:\n",
    "    gps_df['UTC DATE'] = [gps_df['UTC DATE'][k].strip() for k in range(len(gps_df))] # remove initial/final spaces\n",
    "    gps_df['UTC TIME'] = [gps_df['UTC TIME'][k].strip() for k in range(len(gps_df))] # remove initial/final spaces\n",
    "    gps_df['LOCAL DATE'] = [gps_df['LOCAL DATE'][k].strip() for k in range(len(gps_df))] # remove initial/final spaces\n",
    "    gps_df['LOCAL TIME'] = [gps_df['LOCAL TIME'][k].strip() for k in range(len(gps_df))] # remove initial/final spaces\n",
    "    # add datetime column\n",
    "    gps_df['DATETIME'] = pd.to_datetime(gps_df['UTC DATE'] + \" \" + gps_df['UTC TIME'], format=\"%Y/%m/%d\")\n",
    "except:\n",
    "    try:\n",
    "        gps_df['DATE'] = [gps_df['DATE'][k].strip() for k in range(len(gps_df))] # remove initial/final spaces\n",
    "        gps_df['TIME'] = [gps_df['TIME'][k].strip() for k in range(len(gps_df))] # remove initial/final spaces\n",
    "        # add datetime column\n",
    "        gps_df['DATETIME'] = pd.to_datetime(gps_df['DATE'] + \" \" + gps_df['TIME'], format=\"%Y/%m/%d\")\n",
    "    except:\n",
    "        gps_df['UTC'] = [gps_df['UTC'][k].strip() for k in range(len(gps_df))] # remove initial/final spaces\n",
    "        gps_df['LOCAL TIME'] = [gps_df['LOCAL TIME'][k].strip() for k in range(len(gps_df))] # remove initial/final spaces\n",
    "        # add datetime column\n",
    "        gps_df['DATETIME'] = pd.to_datetime(gps_df['UTC'], format=\"%Y/%m/%d\")\n",
    "\n",
    "print(gps_df.shape)\n",
    "#print(gps_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T17:36:12.501796Z",
     "start_time": "2019-11-15T17:36:11.228494Z"
    }
   },
   "outputs": [],
   "source": [
    "gps_df.describe(include='all').transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T17:36:12.710736Z",
     "start_time": "2019-11-15T17:36:12.683830Z"
    }
   },
   "outputs": [],
   "source": [
    "gps_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T08:24:07.727459Z",
     "start_time": "2019-12-03T08:24:07.690520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['------------ Data File Created By ActiGraph GT3XPlus ActiLife v6.13.3 Firmware v2.5.0 date format M/d/yyyy Filter Normal Multiple Incline Limb: Undefined -----------',\n",
       " 'Serial Number: CLE1B36130030',\n",
       " 'Start Time 09:00:00',\n",
       " 'Start Date 7/4/2016',\n",
       " 'Epoch Period (hh:mm:ss) 00:00:10',\n",
       " 'Download Time 15:21:04',\n",
       " 'Download Date 7/13/2016',\n",
       " 'Current Memory Address: 0',\n",
       " 'Current Battery Voltage: 406     Mode = 13',\n",
       " '--------------------------------------------------',\n",
       " '0,0,0,0,0']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read accelerometer data\n",
    "\n",
    "# path = work_dir + acc + file_acc\n",
    "\n",
    "path = \"../corrections/Errors-Habitus/input-habitus/PP001_actigraph_10.csv\" #######\n",
    "\n",
    "acc_list = [line.rstrip('\\n') for line in open(path)]\n",
    "\n",
    "acc_list[0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T08:24:18.049061Z",
     "start_time": "2019-12-03T08:24:18.040787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 09:00:00\n",
      "start date: 7/4/2016\n",
      "time interval: 00:00:10\n",
      "end time: 15:21:04\n",
      "end date: 7/13/2016\n"
     ]
    }
   ],
   "source": [
    "# print metadata\n",
    "\n",
    "start_time = acc_list[2].split()[2]\n",
    "start_date = acc_list[3].split()[2]\n",
    "interval = acc_list[4].split()[3]\n",
    "end_time = acc_list[5].split()[2]\n",
    "end_date = acc_list[6].split()[2]\n",
    "print(\"start time: %s\" % start_time)\n",
    "print(\"start date: %s\" % start_date)\n",
    "print(\"time interval: %s\" % interval)\n",
    "print(\"end time: %s\" % end_time)\n",
    "print(\"end date: %s\" % end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T08:24:21.048051Z",
     "start_time": "2019-12-03T08:24:21.031596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start timestamp: 2016-04-07 09:00:00\n",
      "end timestamp: 2016-07-13 15:21:04\n",
      "interval in sec: 10.0\n",
      "number of acc. events: 80046\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    start_timestamp = dt.datetime.strptime(start_date + \" \" + start_time, '%d/%m/%Y %H:%M:%S')\n",
    "except:\n",
    "    try:\n",
    "        start_timestamp = dt.datetime.strptime(start_date + \" \" + start_time, '%m/%d/%Y %H:%M:%S')\n",
    "    except:\n",
    "        start_timestamp = dt.datetime.strptime(start_date + \" \" + start_time, '%Y/%m/%d %H:%M:%S')\n",
    "    \n",
    "x = time.strptime(interval, '%H:%M:%S')\n",
    "interval = dt.timedelta(hours=x.tm_hour,minutes=x.tm_min,seconds=x.tm_sec)\n",
    "try:\n",
    "    end_timestamp = dt.datetime.strptime(end_date + \" \" + end_time, '%d-%b-%y %H:%M:%S')\n",
    "except:\n",
    "    try:\n",
    "        end_timestamp = dt.datetime.strptime(end_date + \" \" + end_time, '%d-%m-%Y %H:%M:%S')\n",
    "    except:\n",
    "        try:\n",
    "            end_timestamp = dt.datetime.strptime(end_date + \" \" + end_time, '%d/%m/%Y %H:%M:%S')\n",
    "        except:\n",
    "            try:\n",
    "                end_timestamp = dt.datetime.strptime(end_date + \" \" + end_time, '%m/%d/%Y %H:%M:%S')\n",
    "            except:\n",
    "                end_timestamp = dt.datetime.strptime(end_date + \" \" + end_time, '%Y/%m/%d %H:%M:%S')\n",
    "\n",
    "if len(acc_list[10]) < 50: \n",
    "    acc_data = acc_list[10:]\n",
    "else:\n",
    "    acc_data = acc_list[11:]\n",
    "    \n",
    "tot_intervals = len(acc_data)\n",
    "print(\"start timestamp: %s\" % start_timestamp)\n",
    "print(\"end timestamp: %s\" % end_timestamp)\n",
    "print(\"interval in sec: %s\" % interval.total_seconds())\n",
    "print(\"number of acc. events: %d\" % tot_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T08:24:50.582943Z",
     "start_time": "2019-12-03T08:24:50.441185Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATETIME</th>\n",
       "      <th>ACC DATA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-07 09:00:00</td>\n",
       "      <td>0,0,0,0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-07 09:00:10</td>\n",
       "      <td>0,0,0,0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-07 09:00:20</td>\n",
       "      <td>0,0,0,0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-07 09:00:30</td>\n",
       "      <td>0,0,0,0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-04-07 09:00:40</td>\n",
       "      <td>0,0,0,0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-04-07 09:00:50</td>\n",
       "      <td>0,0,0,0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-04-07 09:01:00</td>\n",
       "      <td>0,0,0,0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-04-07 09:01:10</td>\n",
       "      <td>0,0,0,0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016-04-07 09:01:20</td>\n",
       "      <td>0,0,0,0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-04-07 09:01:30</td>\n",
       "      <td>0,0,0,0,0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DATETIME   ACC DATA\n",
       "0 2016-04-07 09:00:00  0,0,0,0,0\n",
       "1 2016-04-07 09:00:10  0,0,0,0,0\n",
       "2 2016-04-07 09:00:20  0,0,0,0,0\n",
       "3 2016-04-07 09:00:30  0,0,0,0,0\n",
       "4 2016-04-07 09:00:40  0,0,0,0,0\n",
       "5 2016-04-07 09:00:50  0,0,0,0,0\n",
       "6 2016-04-07 09:01:00  0,0,0,0,0\n",
       "7 2016-04-07 09:01:10  0,0,0,0,0\n",
       "8 2016-04-07 09:01:20  0,0,0,0,0\n",
       "9 2016-04-07 09:01:30  0,0,0,0,0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create accelerometer dataframe\n",
    "\n",
    "acc_df = pd.DataFrame({})\n",
    "acc_df['DATETIME'] = [start_timestamp + k*interval for k in range(tot_intervals)]\n",
    "acc_df['ACC DATA'] = acc_data\n",
    "acc_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T17:37:10.561542Z",
     "start_time": "2019-11-15T17:36:26.875020Z"
    }
   },
   "outputs": [],
   "source": [
    "# select gps data based on accelerometer timestamps\n",
    "\n",
    "start_time = time.clock()\n",
    "w1 = np.zeros(len(gps_df))\n",
    "#w2 = np.zeros(len(gps_df))\n",
    "w3 = gps_df['DATETIME'].copy()\n",
    "for i in range(len(acc_df)):\n",
    "    w1 = abs((gps_df['DATETIME'] - acc_df['DATETIME'][i]).dt.total_seconds()) < interval.total_seconds()/2 # only one element equal to 1\n",
    "    #w2[w1] = 1  # select indices that match the condition in w1; NOT used\n",
    "    if w1.sum() == 1:  # found a value of gps_df which matches timestamp in acc_df\n",
    "        w3[w1] = acc_df['DATETIME'][i]\n",
    "            \n",
    "print(time.clock() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T17:37:10.567453Z",
     "start_time": "2019-11-15T17:36:29.332Z"
    }
   },
   "outputs": [],
   "source": [
    "# create merged dataframe\n",
    "\n",
    "gps_df2 = gps_df.copy()\n",
    "gps_df2['DATETIME'] = w3\n",
    "merged_df = pd.merge(acc_df, gps_df2, on='DATETIME')\n",
    "merged_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write merged data frame on file\n",
    "try:\n",
    "    os.mkdir(work_dir + merge)\n",
    "    print(\"\\n Output directory: \" + work_dir + merge)\n",
    "except FileExistsError:\n",
    "    print(\"\\n Output directory: \" + work_dir + merge)\n",
    "\n",
    "\n",
    "path = work_dir + merge + file_merge\n",
    "merged_df.to_csv(path)\n",
    "print(\" Output file \" + file_merge + \" added.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
